{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee869855-dba7-4f9e-8a85-9a75f1ae91ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 크롤링 중: 202411190006 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190005 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190004 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190003 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190002 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190001 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n",
      "\n",
      "--- 크롤링 중: 202411190000 ---\n",
      "데이터가 incruit.json 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "# 페이지 정보를 가져오는 함수\n",
    "def get_page_info(contestno):\n",
    "    url = f'https://gongmo.incruit.com/info/gongmolistinfo.asp?contestno={contestno}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "    # HTTP 요청을 보내고 페이지 내용을 받음\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # 요청이 성공했는지 확인\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 필요한 데이터 추출\n",
    "        category = soup.find('p', class_='view--category').get_text(strip=True) if soup.find('p', class_='view--category') else '정보 없음'\n",
    "        title = soup.find('h1', class_='gongmo-view-contents__h1').get_text(strip=True) if soup.find('h1', class_='gongmo-view-contents__h1') else None\n",
    "        \n",
    "        # 제목이 없으면 데이터 저장하지 않음\n",
    "        if not title:\n",
    "            return None\n",
    "        \n",
    "        # 주최자 정보 추출 (p 태그가 포함된 td를 찾아서 텍스트 추출)\n",
    "        organizer_td = soup.find_all('td')[0]  # find_all로 모든 td 요소를 찾음\n",
    "        if organizer_td:\n",
    "            organizer = organizer_td.find('p').get_text(strip=True) if organizer_td.find('p') else '정보 없음'\n",
    "        else:\n",
    "            organizer = '정보 없음'\n",
    "\n",
    "        # 진행상태 정보 추출 (None 체크 추가)\n",
    "        status_span = soup.find_all('td')[1].get_text(strip=True) if len(soup.find_all('td')) > 1 else '정보 없음'\n",
    "        # 접수기간 정보 추출\n",
    "        period_td = soup.find_all('td')[2].get_text(strip=True) if len(soup.find_all('td')) > 2 else '정보 없음'\n",
    "\n",
    "        # 응모대상 정보 추출\n",
    "        target = soup.find_all('td')[3].get_text(strip=True) if len(soup.find_all('td')) > 3 else '정보 없음'\n",
    "\n",
    "        # 시상내역 정보 추출\n",
    "        prize = soup.find_all('td')[4].get_text(strip=True) if len(soup.find_all('td')) > 4 else '정보 없음'\n",
    "\n",
    "        # 링크 정보 추출\n",
    "        link = soup.find('a', class_='c-btn c-btn-orange c-btn-xlg')['href'] if soup.find('a', class_='c-btn c-btn-orange c-btn-xlg') else '정보 없음'\n",
    "\n",
    "        # 이미지 정보 추출\n",
    "        image_div = soup.find('div', class_='gongmo-aside-right__thumbnail')\n",
    "        if image_div and image_div.find('img'):\n",
    "            image = image_div.find('img')['src']\n",
    "        else:\n",
    "            image = '정보 없음'\n",
    "\n",
    "        # 추출한 정보를 딕셔너리로 저장\n",
    "        data = {\n",
    "            \"category\": category,\n",
    "            \"title\": title,\n",
    "            \"organizer\": organizer,  # 수정된 부분\n",
    "            \"status\": status_span,\n",
    "            \"period\": period_td,\n",
    "            \"target\": target,\n",
    "            \"prize\": prize,\n",
    "            \"link\": link,\n",
    "            \"image\": image\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"페이지를 가져오는 데 실패했습니다. 상태 코드: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 크롤링 결과를 JSON 파일로 저장하는 함수\n",
    "def save_to_json(data, filename=\"incruit.json\"):\n",
    "    try:\n",
    "        # 기존 데이터가 있으면 불러오기\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                all_data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            all_data = []\n",
    "\n",
    "        # 새 데이터를 추가\n",
    "        all_data.append(data)\n",
    "\n",
    "        # 파일에 저장\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(all_data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"데이터가 {filename} 파일에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"파일 저장 중 오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 크롤링 시작 함수\n",
    "def crawl():\n",
    "    start_contestno = 202411190006  # 시작 contestno\n",
    "    end_contestno = 202411190000    # 끝 contestno (202409010101)\n",
    "\n",
    "    # contestno가 감소하면서 크롤링 수행\n",
    "    contestno = start_contestno\n",
    "    while contestno >= end_contestno:\n",
    "        print(f\"\\n--- 크롤링 중: {contestno} ---\")\n",
    "        \n",
    "        # 페이지 정보 가져오기\n",
    "        data = get_page_info(str(contestno))\n",
    "        \n",
    "        # 유효한 데이터가 있으면 JSON 파일에 저장\n",
    "        if data:\n",
    "            save_to_json(data)\n",
    "        \n",
    "        # contestno 업데이트 (하나씩 감소)\n",
    "        contestno -= 1\n",
    "        \n",
    "        # 너무 빠르게 요청을 보내지 않도록 대기 시간 추가\n",
    "        time.sleep(1)\n",
    "\n",
    "# 크롤링 실행\n",
    "crawl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e599e5-ab70-4452-9155-c4113d829225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
